# Violence-Detection-Video-Analytics

## YOLO11 + R3D-18 + Multi-Object Tracking + Motion Filtering

This repository contains a **real-time violence (fight) detection system** designed for CCTV and surveillance applications.  
It uses deep learning for person detection, action classification, motion analysis, and temporal validation to deliver highly accurate fight alerts.

---

# ğŸ“Œ Features

### 1. Person Detection â€” _YOLO11_

Detects all people in each frame with high accuracy and speed.

### 2. Fight Classification â€” _3D CNN (R3D-18)_

A custom-trained **3D ResNet-18** model classifies 16-frame video clips as:

- **Fight**
- **Non-Fight**

### 3. Multi-Object Tracking (SORT-like)

Tracks every person across frames and assigns a unique ID, enabling:

- Person-specific predictions
- Temporal stability
- Fight confirmation per individual

### 4. Motion-Based Activity Filtering

Reduces false positives by classifying each tracked person as:

- **Idle** â†’ ignore
- **Walking** â†’ ignore
- **Active movement** â†’ candidate for fight

### 5. 2-Second Confirmation Rule

A fight is only confirmed if:

- Model predicts fight
- Person is active (not standing/walking)
- Condition lasts **>= 2 seconds**

This drastically reduces flicker and false alarms.

### 6. Annotated Output

The system outputs a video with:

- Red bounding boxes
- Text labels like:  
   `FIGHT 87% (active)`  
  Only confirmed fighters are displayed.

---

# ğŸ“‚ Dataset

This project uses the **RWF-2000 dataset**, which contains:

- 2000 surveillance videos
- Two classes: **Fight / Non-Fight**
- Train/Validation split maintained as in original paper

Structure:

```
dataset/
   train/
      Fight/
      NonFight/
   val/
      Fight/
      NonFight/
```

---

# ğŸ§  Model Training

### 1. YOLO11 Detection

Used to generate:

- Bounding boxes
- Person tracking
- Person-level cropped clips

### 2. R3D-18 Action Classifier

Trained on the generated clips:

- Input: 16Ã—112Ã—112 frames
- Labels assigned based on video name (Fight=1, NonFight=0)
- Achieved **~78â€“80% validation accuracy**

---

# ğŸ—ï¸ System Architecture

```
Video â†’ YOLO Person Detection â†’ Multi-Object Tracking
      â†’ Per-Person Clip Buffer â†’ R3D-18 Classification
      â†’ Motion Activity Check â†’ 2-Second Fight Confirmation
      â†’ Final Annotated Output Video
```

---

# ğŸ“¦ Directory Structure (recommended)

```
violence-detection/
â”‚
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ val/
â”‚
â”œâ”€â”€ workspace/
â”‚   â”œâ”€â”€ detections/       # YOLO detection JSONs
â”‚   â”œâ”€â”€ tracks/           # Tracking JSONs
â”‚   â”œâ”€â”€ frames/           # Optional frame dumps
â”‚   â”œâ”€â”€ clips/            # 16-frame person clips (.npy)
â”‚   â”œâ”€â”€ models/           # Checkpoints + best model
â”‚   â””â”€â”€ inference_outputs/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess_detect.py
â”‚   â”œâ”€â”€ preprocess_track.py
â”‚   â”œâ”€â”€ preprocess_clips.py
â”‚   â”œâ”€â”€ train_classifier.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â””â”€â”€ utils.py
â”‚
â””â”€â”€ README.md
```

---

# â–¶ï¸ How to Run Inference

```bash
python src/inference.py --video Test-Video.mp4
```

This generates:

```
workspace/inference_outputs/Test-Video-Output.mp4
```

---

# ğŸ¤– Technologies Used

- **Python**
- **PyTorch**
- **TorchVision**
- **Ultralytics YOLO**
- **OpenCV**
- **NumPy**

---

# ğŸ› ï¸ Requirements

```
torch
torchvision
ultralytics
opencv-python
numpy
```

Install:

```bash
pip install -r requirements.txt
```

# Violence Detection Images

### Output 1

![Output 1](assets/output1.png)

### Output 2

![Output 2](assets/output2.png)

# ğŸš€ Applications

- Smart Surveillance
- Public Safety Monitoring
- Industrial Safety Systems
- Smart City Solutions
- Automated Security Alarms

---
